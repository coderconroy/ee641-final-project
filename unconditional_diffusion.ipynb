{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unconditional Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "from utils.models import UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # data_dir = r\"D:\\Data\\Datasets\\landscape\"\n",
    "    data_dir = r\"D:\\Data\\Datasets\\S2TLD_extracted_small\"\n",
    "    model_name = \"s2tld2\"\n",
    "    diffusion_steps = 1000\n",
    "    learn_rate = 1e-4\n",
    "    batch_size = 3\n",
    "    image_size = 64\n",
    "    num_samples = 3  # Number of samples to generate\n",
    "    sample_freq_epochs = 3  # Frequency with with to generate samples (i.e. every x epochs)\n",
    "    load_from_checkpoint = True  # Start training from checkpoint if one exists for the given model name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_batch(image_batch, filename):\n",
    "    \"\"\"\n",
    "    Save a batch of image tensors to disk as a single grid image\n",
    "\n",
    "    Parameters:\n",
    "    - image_batch: batch of unnormalized image tensors with shape (batch_size, channels, height, width)\n",
    "    - filename: File path and name to save image without extension \n",
    "    \"\"\"\n",
    "    # Normalize images to [0, 1]\n",
    "    image_batch = torch.clamp(image_batch * 0.5 + 0.5, 0, 1)\n",
    "\n",
    "    # Create image grid and convert to PIL image\n",
    "    image_grid = make_grid(image_batch)\n",
    "    image_grid = np.transpose(image_grid.cpu().numpy(), (1, 2, 0))\n",
    "    pil_image = Image.fromarray((image_grid * 255).astype(np.uint8))\n",
    "\n",
    "    # Split the path into directory and filename\n",
    "    path = f\"{filename}.png\"\n",
    "    directory, filename = os.path.split(path)\n",
    "\n",
    "    # Create the directory if it does not exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Save image to disk\n",
    "    pil_image.save(path)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    # Split the path into directory and filename\n",
    "    path = f\"{filename}.pt\"\n",
    "    directory, filename = os.path.split(path)\n",
    "\n",
    "    # Create the directory if it does not exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Save checkpoint state\n",
    "    torch.save(state, path)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer, diffusion):\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    diffusion.load_state_dict(checkpoint['diffusion'])\n",
    "    return checkpoint['epoch'], checkpoint['loss_history']\n",
    "\n",
    "\n",
    "def get_dataloader(data_dir, batch_size, image_size):\n",
    "    # Define image transformations\n",
    "    # TODO: Review if this can be improved.\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(round(image_size * 5/4)),\n",
    "        transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize from [0, 1] to [-1, 1]\n",
    "    ])\n",
    "\n",
    "    # Create an instance of the ImageFolder dataset\n",
    "    dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "    print(dataset[0][0].size())\n",
    "\n",
    "    # Create a DataLoader to batch and shuffle the data\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion:\n",
    "    def __init__(self, device, diffusion_steps=1000, image_size=64, beta_1=1e-4, beta_T=0.02):\n",
    "        # Initialize class variables\n",
    "        self.diffusion_steps = diffusion_steps\n",
    "        self.device = device\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_T = beta_T\n",
    "\n",
    "        # Compute beta decay schedule\n",
    "        self.compute_beta_schedule()\n",
    "\n",
    "    def compute_beta_schedule(self):\n",
    "        self.beta = torch.linspace(self.beta_1, self.beta_T, self.diffusion_steps, device=self.device)\n",
    "        self.alpha = 1 - self.beta\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "\n",
    "    def apply_noise(self, x_0):\n",
    "        \"\"\"\n",
    "        Apply noise to batch of image tensors based on beta decay schedule at a uniformly distributed time step sample.\n",
    "        \"\"\"\n",
    "        # Sample timestep: t âˆ¼ Uniform({1, . . . , T})\n",
    "        t = torch.randint(1, self.diffusion_steps + 1, (x_0.shape[0],), device=self.device)\n",
    "\n",
    "        # Sample noise: epsilon ~ N(0,I)\n",
    "        epsilon = torch.randn_like(x_0, device=self.device)\n",
    "\n",
    "        # Apply noise to image based on beta schedule\n",
    "        sqrt_alpha_bar_t = torch.sqrt(self.alpha_bar[t-1]).view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha_bar_t = torch.sqrt(1 - self.alpha_bar[t-1]).view(-1, 1, 1, 1)\n",
    "        x_t = (sqrt_alpha_bar_t * x_0) + (sqrt_one_minus_alpha_bar_t * epsilon)\n",
    "\n",
    "        return x_t, t, epsilon\n",
    "    \n",
    "    def remove_noise(self, x_t, t, epsilon_pred):\n",
    "        if t > 1:\n",
    "            z = torch.normal(0, 1, x_t.size(), device=Config.device)\n",
    "        else:\n",
    "            z = torch.zeros(x_t.size(), device=Config.device)\n",
    "\n",
    "        inv_sqrt_alpha_t = 1 / torch.sqrt(self.alpha[t-1])\n",
    "        one_minus_alpha_t = 1 - self.alpha[t-1]\n",
    "        sqrt_one_minus_alpha_bar_t = torch.sqrt(1 - self.alpha_bar[t-1])\n",
    "        subtract = (one_minus_alpha_t / sqrt_one_minus_alpha_bar_t) * epsilon_pred\n",
    "        sigma_t = torch.sqrt(self.beta[t-1])\n",
    "\n",
    "        return inv_sqrt_alpha_t * (x_t - subtract) + sigma_t * z\n",
    "        \n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"\n",
    "        Get the current state of the diffusion model for checkpointing.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'diffusion_steps': self.diffusion_steps,\n",
    "            'beta_1': self.beta_1,\n",
    "            'beta_T': self.beta_T,\n",
    "            'alpha_t': self.alpha,\n",
    "            'alpha_bar_t': self.alpha_bar\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state):\n",
    "        \"\"\"\n",
    "        Load the state of the diffusion model from a checkpoint.\n",
    "        \"\"\"\n",
    "        self.diffusion_steps = state['diffusion_steps']\n",
    "        self.beta_1 = state['beta_1']\n",
    "        self.beta_T = state['beta_T']\n",
    "        self.compute_beta_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_epochs, dataloader, checkpoint=None):\n",
    "\n",
    "    # Initialize other training parameters\n",
    "    criterion = nn.MSELoss()\n",
    "    diffusion = Diffusion(device=Config.device, diffusion_steps = Config.diffusion_steps)\n",
    "    model = UNet(device=Config.device).to(Config.device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=Config.learn_rate)\n",
    "\n",
    "    if checkpoint:\n",
    "        # Initialize parameters for training from last checkpoint\n",
    "        start_epoch, loss_history = load_checkpoint(checkpoint, model, optimizer, diffusion)\n",
    "    else:\n",
    "        # Initialize parameters for training from scratch\n",
    "        start_epoch = 0\n",
    "        loss_history = []\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()  # Set to model to train mode\n",
    "        epoch_loss = 0\n",
    "\n",
    "        # Train model (algorithm 1)\n",
    "        for x_0, _ in tqdm(dataloader, desc=\"Training\"):\n",
    "            x_0 = x_0.to(Config.device)  # Move images to active compute device\n",
    "\n",
    "            x_t, t, epsilon = diffusion.apply_noise(x_0)  # Apply noise to images (forward process)\n",
    "            epsilon_pred = model(x_t, t)  # Predict noise using model (reverse process)\n",
    "            batch_loss = criterion(epsilon_pred, epsilon)  # Compute loss\n",
    "\n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "        # Update loss history\n",
    "        loss_history.append(epoch_loss)\n",
    "\n",
    "        # Display epoch and loss\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss/len(dataloader):.4f}\")\n",
    "\n",
    "        # Save model training checkpoint\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'loss_history': loss_history,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'diffusion': diffusion.state_dict()\n",
    "        }, os.path.join(\"models\", Config.model_name, f\"checkpoint\"))\n",
    "\n",
    "        # Sample images from model (algorithm 2)\n",
    "        if (epoch + 1) % Config.sample_freq_epochs == 0:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                sample_shape = (Config.num_samples, *dataloader.dataset[0][0].size())\n",
    "                x_t = torch.normal(0, 1, sample_shape, device=Config.device)  # Initialized to x_T\n",
    "\n",
    "                # Iterate over all reverse diffusion time steps from T to 1\n",
    "                for t in tqdm(range(diffusion.diffusion_steps, 0, -1), desc=\"Sampling\"):\n",
    "                    t_vec = t * torch.ones(x_t.shape[0], device=Config.device)\n",
    "                    epsilon_pred = model(x_t, t_vec)\n",
    "                    x_t_minus_1 = diffusion.remove_noise(x_t, t, epsilon_pred)\n",
    "                    x_t = x_t_minus_1\n",
    "\n",
    "                save_image_batch(x_t, os.path.join(\"results\", Config.model_name, f\"{epoch + 1}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint\n",
    "if Config.load_from_checkpoint:\n",
    "    checkpoint = torch.load(os.path.join(\"models\", Config.model_name, f\"checkpoint.pt\"))\n",
    "else:\n",
    "    checkpoint = None\n",
    "\n",
    "# Initialize dataloader\n",
    "dataloader = get_dataloader(Config.data_dir, Config.batch_size, Config.image_size)\n",
    "\n",
    "# Train model\n",
    "torch.cuda.empty_cache()\n",
    "train_model(500, dataloader, checkpoint, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee641",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
