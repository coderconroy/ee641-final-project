{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Diffusion Model - V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from utils.models_v2 import UNet, EMA\n",
    "from utils.diffusion_v2 import Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # data_dir = r\"D:\\Data\\Datasets\\landscape\"\n",
    "    data_dir = r\"D:\\Data\\Datasets\\S2TLD_extracted_small\"\n",
    "    model_name = \"s2tld_cond1_v2\"\n",
    "    diffusion_steps = 1000\n",
    "    learn_rate = 1e-4\n",
    "    batch_size = 3\n",
    "    image_size = 64\n",
    "    num_samples = 3  # Number of samples to generate\n",
    "    sample_freq_epochs = 3  # Frequency with with to generate samples (i.e. every x epochs)\n",
    "    load_from_checkpoint = True  # Start training from checkpoint if one exists for the given model name\n",
    "    train_unconditional_prob = 0.1  # Probability of training model unconditionally for a given batch\n",
    "    cfg_scale = 3  # Classifier free guidance scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_batch(image_batch, filename):\n",
    "    \"\"\"\n",
    "    Save a batch of image tensors to disk as a single grid image\n",
    "\n",
    "    Parameters:\n",
    "    - image_batch: batch of unnormalized image tensors with shape (batch_size, channels, height, width)\n",
    "    - filename: File path and name to save image without extension \n",
    "    \"\"\"\n",
    "    # Normalize images to [0, 1]\n",
    "    image_batch = torch.clamp(image_batch * 0.5 + 0.5, 0, 1)\n",
    "\n",
    "    # Create image grid and convert to PIL image\n",
    "    image_grid = make_grid(image_batch)\n",
    "    image_grid = np.transpose(image_grid.cpu().numpy(), (1, 2, 0))\n",
    "    pil_image = Image.fromarray((image_grid * 255).astype(np.uint8))\n",
    "\n",
    "    # Split the path into directory and filename\n",
    "    path = f\"{filename}.png\"\n",
    "    directory, filename = os.path.split(path)\n",
    "\n",
    "    # Create the directory if it does not exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Save image to disk\n",
    "    pil_image.save(path)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    # Split the path into directory and filename\n",
    "    path = f\"{filename}.pt\"\n",
    "    directory, filename = os.path.split(path)\n",
    "\n",
    "    # Create the directory if it does not exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Save checkpoint state\n",
    "    torch.save(state, path)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer, diffusion, ema_model=None):\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    diffusion.load_state_dict(checkpoint['diffusion'])\n",
    "    if ema_model:\n",
    "        ema_model.load_state_dict(checkpoint['ema_state_dict'])\n",
    "    return checkpoint['epoch'], checkpoint['loss_history']\n",
    "\n",
    "\n",
    "def get_dataloader(data_dir, batch_size, image_size):\n",
    "    # Define image transformations\n",
    "    # TODO: Review if this can be improved.\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(round(image_size * 5/4)),\n",
    "        transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize from [0, 1] to [-1, 1]\n",
    "    ])\n",
    "\n",
    "    # Create an instance of the ImageFolder dataset\n",
    "    dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "    print(dataset[0][0].size())\n",
    "\n",
    "    # Create a DataLoader to batch and shuffle the data\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_epochs, dataloader, checkpoint=None):\n",
    "\n",
    "    # Initialize other training parameters\n",
    "    num_classes = len(dataloader.dataset.classes)\n",
    "    criterion = nn.MSELoss()\n",
    "    diffusion = Diffusion(device=Config.device, diffusion_steps = Config.diffusion_steps)\n",
    "    model = UNet(num_classes=num_classes, device=Config.device).to(Config.device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=Config.learn_rate)\n",
    "\n",
    "    # Initialize EMA model variation\n",
    "    ema = EMA(0.995)\n",
    "    ema_model = deepcopy(model).eval().requires_grad_(False)\n",
    "\n",
    "    if checkpoint:\n",
    "        # Initialize parameters for training from last checkpoint\n",
    "        start_epoch, loss_history = load_checkpoint(checkpoint, model, optimizer, diffusion, ema_model)\n",
    "    else:\n",
    "        # Initialize parameters for training from scratch\n",
    "        start_epoch = 0\n",
    "        loss_history = []\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()  # Set to model to train mode\n",
    "        epoch_loss = 0\n",
    "\n",
    "        # Train model (algorithm 1)\n",
    "        for x_0, y in tqdm(dataloader, desc=\"Training\"):\n",
    "            x_0 = x_0.to(Config.device)  # Move images to active compute device\n",
    "            y = None if torch.rand(1) < Config.train_unconditional_prob else y.to(Config.device) # Randomly choose conditional/unconitional training\n",
    "\n",
    "            x_t, t, epsilon = diffusion.apply_noise(x_0)  # Apply noise to images (forward process)\n",
    "            epsilon_pred = model(x_t, t, y)  # Predict noise using model (reverse process)\n",
    "            batch_loss = criterion(epsilon_pred, epsilon)  # Compute loss\n",
    "\n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "            # Update EMA model\n",
    "            ema.step_ema(ema_model, model)\n",
    "\n",
    "        # Update loss history\n",
    "        loss_history.append(epoch_loss)\n",
    "\n",
    "        # Display epoch and loss\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss/len(dataloader):.4f}\")\n",
    "\n",
    "        # Save model training checkpoint\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'loss_history': loss_history,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'diffusion': diffusion.state_dict(),\n",
    "            'ema_state_dict': ema_model.state_dict()\n",
    "        }, os.path.join(\"models\", Config.model_name, f\"checkpoint\"))\n",
    "\n",
    "        # Sample images from model (algorithm 2)\n",
    "        if (epoch + 1) % Config.sample_freq_epochs == 0:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                sample_shape = (Config.num_samples, *dataloader.dataset[0][0].size())\n",
    "                x_t = torch.normal(0, 1, sample_shape, device=Config.device)  # Initialized to x_T\n",
    "\n",
    "                # Iterate over all reverse diffusion time steps from T to 1\n",
    "                for t in tqdm(range(diffusion.diffusion_steps, 0, -1), desc=\"Sampling\"):\n",
    "                    t_vec = t * torch.ones(x_t.shape[0], device=Config.device)\n",
    "\n",
    "                    label = torch.randint(0, num_classes, (1,)).item()\n",
    "                    y = torch.full((x_t.shape[0],), label, dtype=torch.long).to(Config.device)\n",
    "                    epsilon_pred = model(x_t, t_vec, y)\n",
    "                    if Config.cfg_scale > 0:\n",
    "                        unc_epsilon_pred = model(x_t, t_vec, None)\n",
    "                        epsilon_pred = torch.lerp(unc_epsilon_pred, epsilon_pred, Config.cfg_scale)\n",
    "\n",
    "                    x_t_minus_1 = diffusion.remove_noise(x_t, t, epsilon_pred)\n",
    "                    x_t = x_t_minus_1\n",
    "\n",
    "                save_image_batch(x_t, os.path.join(\"results\", Config.model_name, f\"{epoch + 1}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint\n",
    "if Config.load_from_checkpoint:\n",
    "    checkpoint = torch.load(os.path.join(\"models\", Config.model_name, f\"checkpoint.pt\"))\n",
    "else:\n",
    "    checkpoint = None\n",
    "\n",
    "# Initialize dataloader\n",
    "dataloader = get_dataloader(Config.data_dir, Config.batch_size, Config.image_size)\n",
    "\n",
    "# Train model\n",
    "# {'green': 0, 'off': 1, 'red': 2, 'yellow': 3}\n",
    "torch.cuda.empty_cache()\n",
    "train_model(1000, dataloader, checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee641",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
