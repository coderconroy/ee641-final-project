{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lisa Dataset Extraction\n",
    "Script to extract square images of traffic lights from Lisa traffic light dataset. The Lisa dataset can be downloaded here:\n",
    "\n",
    "https://www.kaggle.com/datasets/mbornoe/lisa-traffic-light-dataset\n",
    "\n",
    "The dataset does not need to be altered in any way for this script to run correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the output data directory exists before running this script\n",
    "OUTPUT_DATA_DIR = 'D:\\Data\\Datasets\\lisa_traffic_light_extracted'\n",
    "DATA_DIR = 'D:\\Data\\Datasets\\lisa_traffic_light'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sequences\n",
    "sequences = {'dayTrain': ['dayClip1', 'dayClip2', 'dayClip3', 'dayClip4', 'dayClip5', 'dayClip6', 'dayClip7', \n",
    "                          'dayClip8', 'dayClip9', 'dayClip10', 'dayClip11', 'dayClip12', 'dayClip13'],\n",
    "            'daySequence1': ['']}\n",
    "\n",
    "# Load annotations\n",
    "dfs = []\n",
    "for seq in sequences.keys():\n",
    "    for subseq in sequences[seq]:\n",
    "        annotations = os.path.join(DATA_DIR, 'Annotations', 'Annotations', seq, subseq, 'frameAnnotationsBOX.csv')\n",
    "        seq_df = pd.read_csv(annotations, delimiter=';')\n",
    "\n",
    "        # Add 'sequence' and 'subsequence' columns\n",
    "        seq_df['sequence'] = seq\n",
    "        seq_df['subsequence'] = subseq\n",
    "\n",
    "        # Append to the combined DataFrame\n",
    "        dfs.append(seq_df)\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Compute traffic light width and height columns\n",
    "df['width'] = df['Lower right corner X'] - df['Upper left corner X']\n",
    "df['height'] = df['Lower right corner Y'] - df['Upper left corner Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "image_size = 80  # Extracted square image side lengths\n",
    "height_thresh = 32  # Minimum traffic light height\n",
    "scale = image_size / height_thresh\n",
    "\n",
    "# Ensure the directory exists\n",
    "classes = df['Annotation tag'].unique()\n",
    "for cls in classes:\n",
    "    output_dir = os.path.join(OUTPUT_DATA_DIR, cls)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Filter for largest traffic lights and group by filename\n",
    "filtered_df = df[df['height'] >= height_thresh]\n",
    "grouped = filtered_df.groupby('Filename')\n",
    "\n",
    "# Iterate through each group\n",
    "for filepath, group in tqdm(grouped, desc=\"Processing images\"):\n",
    "    # Extract sequence for group. Assumes the sequence will be the same for all rows in the group\n",
    "    seq = group['sequence'].values.tolist()[0]\n",
    "    subseq = group['subsequence'].values.tolist()[0]\n",
    "\n",
    "    # Get image file path\n",
    "    basename = os.path.basename(filepath)\n",
    "    filenum = re.search(r'(\\d+)\\.jpg$', basename).group(1)\n",
    "    filename = os.path.join(DATA_DIR, seq, seq, subseq, 'frames', basename)\n",
    "    \n",
    "    # Get bounding box coordinates and class\n",
    "    bounding_boxes = group[['Upper left corner X', 'Upper left corner Y', 'Lower right corner X', \n",
    "                            'Lower right corner Y']].values.tolist()\n",
    "    classes = group['Annotation tag'].values.tolist()\n",
    "    \n",
    "    img = Image.open(filename)\n",
    "    for i, box in enumerate(bounding_boxes):\n",
    "        # Access columns by name\n",
    "        cls = classes[i]\n",
    "\n",
    "        # Calculating the center of the bounding box\n",
    "        center_x = (box[0] + box[2]) / 2\n",
    "        center_y = (box[1] + box[3]) / 2\n",
    "\n",
    "        # Determine largest traffic light dimension and use to determine the size of the square to be extracted\n",
    "        box_width = box[2] - box[0]\n",
    "        box_height = box[3] - box[1]\n",
    "        largest_dimension = max(box_width, box_height) * scale\n",
    "\n",
    "        # Creating a new square bounding box\n",
    "        half_size = largest_dimension / 2\n",
    "        new_box = [\n",
    "            max(center_x - half_size, 0), # left\n",
    "            max(center_y - half_size, 0), # upper\n",
    "            min(center_x + half_size, img.width), # right\n",
    "            min(center_y + half_size, img.height) # lower\n",
    "        ]\n",
    "\n",
    "        # Cropping the image\n",
    "        cropped_img = img.crop(new_box)\n",
    "\n",
    "        # Resizing the image to 64x64\n",
    "        cropped_img = cropped_img.resize((image_size, image_size))\n",
    "\n",
    "        # Constructing the filename using the counter\n",
    "        filename = f\"{seq}_{subseq}_{filenum}_{i}.jpg\"\n",
    "        file_path = os.path.join(OUTPUT_DATA_DIR, cls, filename)\n",
    "\n",
    "        # Save the cropped image\n",
    "        cropped_img.save(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered Dataset Statistics\n",
    "Statistics describing the dataset after annotations which do not contain traffic lights that meet the height threshold are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['Annotation tag'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee641",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
