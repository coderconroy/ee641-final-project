{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SJTU Small Traffic Light Dataset (S2TLD) Extraction\n",
    "Script to extract square images of traffic lights from SJTU Small Traffic Light Dataset. The dataset can be found here:\n",
    "\n",
    "https://github.com/Thinklab-SJTU/S2TLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the output data directory exists before running this script\n",
    "split_classes = True\n",
    "\n",
    "# DATA_DIR = r'D:\\Data\\Datasets\\S2TLD\\1080p'\n",
    "# OUTPUT_DATA_DIR = 'D:\\Data\\Datasets\\S2TLD_extracted'\n",
    "\n",
    "DATA_DIR = r'D:\\Data\\Datasets\\S2TLD\\720p'\n",
    "OUTPUT_DATA_DIR = 'D:\\Data\\Datasets\\S2TLD_extracted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse XML and extract data\n",
    "def parse_annotation(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract image properties\n",
    "    filename = root.find('filename').text\n",
    "    folder = root.find('folder').text if root.find('folder') is not None else None\n",
    "    database = root.find('database').text if root.find('database') is not None else None\n",
    "    annotation_info = root.find('annotation').text if root.find('annotation') is not None else None\n",
    "    image_info = root.find('image').text if root.find('image') is not None else None\n",
    "    segmented = root.find('segmented').text if root.find('segmented') is not None else None\n",
    "\n",
    "    size_element = root.find('size')\n",
    "    size = {\n",
    "        'height': int(size_element.find('height').text),\n",
    "        'width': int(size_element.find('width').text),\n",
    "        'depth': int(size_element.find('depth').text)\n",
    "    } if size_element is not None else None\n",
    "\n",
    "    # List to hold all objects' data\n",
    "    objects_data = []\n",
    "\n",
    "    # Iterate through all objects in the XML\n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text\n",
    "        bndbox = obj.find('bndbox')\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "        object_data = [filename, folder, database, annotation_info, image_info, size['height'], size['width'], size['depth'], segmented, name, xmin, ymin, xmax, ymax]\n",
    "        objects_data.append(object_data)\n",
    "\n",
    "    return objects_data\n",
    "\n",
    "# Process all XML files in the Annotations directory\n",
    "annotations_path = os.path.join(DATA_DIR, 'Annotations')\n",
    "all_objects = []\n",
    "\n",
    "for xml_file in tqdm(os.listdir(annotations_path), desc=\"Processing XML files\"):\n",
    "    if xml_file.endswith('.xml'):\n",
    "        xml_path = os.path.join(annotations_path, xml_file)\n",
    "        objects_data = parse_annotation(xml_path)\n",
    "        all_objects.extend(objects_data)\n",
    "\n",
    "# Create DataFrame with all fields\n",
    "columns = ['Filename', 'Folder', 'Database', 'Annotation Info', 'Image Info', 'Image Height', 'Image Width', 'Image Depth', 'Segmented', 'Annotation tag', 'Upper left corner X', 'Upper left corner Y', 'Lower right corner X', 'Lower right corner Y']\n",
    "df = pd.DataFrame(all_objects, columns=columns)\n",
    "\n",
    "# Compute traffic light width and height columns\n",
    "df['width'] = df['Lower right corner X'] - df['Upper left corner X']\n",
    "df['height'] = df['Lower right corner Y'] - df['Upper left corner Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe dataframe statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "image_size = 80  # Extracted square image side lengths\n",
    "height_thresh = 40  # Minimum traffic light height\n",
    "scale = image_size / height_thresh\n",
    "\n",
    "# Ensure the directory exists\n",
    "classes = df['Annotation tag'].unique()\n",
    "if split_classes:\n",
    "    for cls in classes:\n",
    "        output_dir = os.path.join(OUTPUT_DATA_DIR, cls)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "else:\n",
    "    output_dir = os.path.join(OUTPUT_DATA_DIR, \"all\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Filter for largest traffic lights and group by filename\n",
    "filtered_df = df[df['height'] >= height_thresh]\n",
    "grouped = filtered_df.groupby('Filename')\n",
    "\n",
    "# Print number of instances:\n",
    "print(f\"Found {len(filtered_df)} instances\")\n",
    "\n",
    "# Iterate through each group\n",
    "for filepath, group in tqdm(grouped, desc=\"Processing images\"):\n",
    "    # Get image file path\n",
    "    basename = os.path.basename(filepath)\n",
    "    filenum = re.search(r'(\\d+)\\.jpg$', basename).group(1)\n",
    "    filename = os.path.join(DATA_DIR, \"JPEGImages\", basename)\n",
    "    \n",
    "    # Get bounding box coordinates and class\n",
    "    bounding_boxes = group[['Upper left corner X', 'Upper left corner Y', 'Lower right corner X', \n",
    "                            'Lower right corner Y']].values.tolist()\n",
    "    classes = group['Annotation tag'].values.tolist()\n",
    "\n",
    "    try:\n",
    "        pattern = r'(\\d{4}-\\d{2}-\\d{2}) (\\d{2}):(\\d{2}):(\\d{2}\\.\\d+)'\n",
    "        new_filename = re.sub(pattern, r'\\1 \\2_\\3_\\4', filename)\n",
    "        img = Image.open(new_filename)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    for i, box in enumerate(bounding_boxes):\n",
    "        # Access columns by name\n",
    "        cls = classes[i]\n",
    "\n",
    "        # Calculating the center of the bounding box\n",
    "        center_x = (box[0] + box[2]) / 2\n",
    "        center_y = (box[1] + box[3]) / 2\n",
    "\n",
    "        # Determine largest traffic light dimension and use to determine the size of the square to be extracted\n",
    "        box_width = box[2] - box[0]\n",
    "        box_height = box[3] - box[1]\n",
    "        largest_dimension = max(box_width, box_height) * scale\n",
    "\n",
    "        # Creating a new square bounding box\n",
    "        half_size = largest_dimension / 2\n",
    "        new_box = [\n",
    "            max(center_x - half_size, 0), # left\n",
    "            max(center_y - half_size, 0), # upper\n",
    "            min(center_x + half_size, img.width), # right\n",
    "            min(center_y + half_size, img.height) # lower\n",
    "        ]\n",
    "\n",
    "        # Cropping the image\n",
    "        cropped_img = img.crop(new_box)\n",
    "\n",
    "        # Resizing the image to 64x64\n",
    "        cropped_img = cropped_img.resize((image_size, image_size))\n",
    "\n",
    "        # Constructing the filename using the counter\n",
    "        filename = f\"{filenum}_{i}.jpg\"\n",
    "        if split_classes:\n",
    "            file_path = os.path.join(OUTPUT_DATA_DIR, cls, filename)\n",
    "        else:\n",
    "            file_path = os.path.join(OUTPUT_DATA_DIR, \"all\", filename)\n",
    "\n",
    "        # Save the cropped image\n",
    "        cropped_img.save(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered Dataset Statistics\n",
    "Statistics describing the dataset after annotations which do not contain traffic lights that meet the height threshold are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['Annotation tag'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee641",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
