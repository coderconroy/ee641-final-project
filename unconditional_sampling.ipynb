{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unconditional Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Third-party library imports\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Local module imports\n",
    "from utils.models import UNet\n",
    "from utils.diffusion import Diffusion\n",
    "from utils.utils import load_model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_name = \"s2tld1\"\n",
    "    checkpoint_name = \"checkpoint-400\"\n",
    "    batch_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save a single image\n",
    "def save_image(image, filename):\n",
    "    # Normalize the image\n",
    "    image = torch.clamp(image * 0.5 + 0.5, 0, 1)\n",
    "\n",
    "    image = np.transpose(image.cpu().numpy(), (1, 2, 0))\n",
    "    pil_image = Image.fromarray((image * 255).astype(np.uint8))\n",
    "\n",
    "    # Split the path into directory and filename\n",
    "    path = f\"{filename}.png\"\n",
    "    directory, filename = os.path.split(path)\n",
    "\n",
    "    # Create the directory if it does not exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Save image to disk\n",
    "    pil_image.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the next available sample number\n",
    "def find_next_sample_num(directory):\n",
    "    # Find all entries (directories or files) that match the pattern\n",
    "    pattern = re.compile(r'^\\d{5}$|^(\\d{5})\\.png$')\n",
    "    numeric_entries = [entry for entry in os.listdir(directory) if pattern.match(entry)]\n",
    "    numeric_values = [int(re.match(r'(\\d{5})', entry).group(1)) for entry in numeric_entries]\n",
    "\n",
    "    # Get next sample number\n",
    "    return 0 if not numeric_values else max(numeric_values) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample images from the model\n",
    "def sample_model(checkpoint, num_batches, batch_size, save_process_imgs=False, num_steps=500):\n",
    "    # Load model\n",
    "    diffusion = Diffusion(device=Config.device)\n",
    "    model = UNet().to(Config.device)\n",
    "    load_model_eval(checkpoint, model, diffusion)\n",
    "    single_sample_num = 0\n",
    "\n",
    "    # Handling directories for saving process images or single images\n",
    "    if save_process_imgs:\n",
    "        # Create directory for each sample and its intermediate images\n",
    "        base_dir = os.path.join(\"samples\", Config.model_name, \"process\")\n",
    "        sample_num = find_next_sample_num(base_dir)\n",
    "        num_samples = num_batches * batch_size\n",
    "        sample_dirs = []\n",
    "        for i in range(sample_num, sample_num + num_samples):\n",
    "            single_sample_dir = os.path.join(base_dir, f\"{i:05d}\")\n",
    "            sample_dirs.append(single_sample_dir)\n",
    "            os.makedirs(single_sample_dir, exist_ok=True)\n",
    "    else:\n",
    "        # Create output directory\n",
    "        single_sample_dir = os.path.join(\"samples\", Config.model_name, \"single\")\n",
    "        os.makedirs(single_sample_dir, exist_ok=True)\n",
    "        single_sample_num = find_next_sample_num(single_sample_dir)\n",
    "\n",
    "    # Sample images from model (algorithm 2)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            # Initialize starting sample noise\n",
    "            sample_shape = (batch_size, 3, 64, 64)\n",
    "            x_t = torch.normal(0, 1, sample_shape, device=Config.device)  # Initialized to x_T\n",
    "\n",
    "            # Get t values to save intermediate images for in the diffusion process\n",
    "            save_t_steps = np.linspace(0, diffusion.diffusion_steps, num_steps, dtype=int, endpoint=False).tolist()\n",
    "\n",
    "            # Save initial pure noise image (in process image directory)\n",
    "            if save_process_imgs:\n",
    "                for j in range(batch_size):\n",
    "                    save_image(x_t[j], os.path.join(sample_dirs[batch_size * i + j], f\"{diffusion.diffusion_steps:06d}\"))\n",
    "\n",
    "            # Iterate over all reverse diffusion time steps from T to 1\n",
    "            for t in tqdm(range(diffusion.diffusion_steps, 0, -1), desc=f\"Sampling - Batch {i+1}/{num_batches}\"):\n",
    "                t_vec = t * torch.ones(x_t.shape[0], device=Config.device)\n",
    "                epsilon_pred = model(x_t, t_vec)\n",
    "                x_t_minus_1 = diffusion.remove_noise(x_t, t, epsilon_pred)\n",
    "                x_t = x_t_minus_1\n",
    "\n",
    "                # Save intermediate images (in process image directory)\n",
    "                if save_process_imgs and t-1 == save_t_steps[-1]:\n",
    "                    save_t_steps.pop()\n",
    "                    for j in range(batch_size):\n",
    "                        save_image(x_t[j], os.path.join(sample_dirs[batch_size * i + j], f\"{t-1:06d}\"))\n",
    "\n",
    "            # Save final images (in single image directory)\n",
    "            for j in range(batch_size):            \n",
    "                save_image(x_t[j], os.path.join(single_sample_dir, f\"{single_sample_num:06d}\"))\n",
    "                single_sample_num += 1\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create an image grid from a list of images\n",
    "def create_image_grid(images, grid_size):\n",
    "    # Assume all images are the same size\n",
    "    img_height, img_width = images[0].shape[:2]\n",
    "\n",
    "    # Initialize blank image for the grid\n",
    "    grid_img = np.zeros((img_height * grid_size[0], img_width * grid_size[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Place each image in its respective position\n",
    "    num_blocks = grid_size[0] * grid_size[1]\n",
    "    for idx, img in enumerate(images[:num_blocks]):\n",
    "        row = idx // grid_size[1]\n",
    "        col = idx % grid_size[1]\n",
    "        grid_img[row*img_height:(row+1)*img_height, col*img_width:(col+1)*img_width] = img\n",
    "\n",
    "    return grid_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a video from a several samples and their intermediate diffusion images\n",
    "def create_video(process_dir, video_name, grid_size, fps=30):\n",
    "    # Find all directories with 5 numeric digits\n",
    "    sample_dirs = [dir for dir in os.listdir(process_dir) if dir.isdigit() and len(dir) == 5]\n",
    "\n",
    "    # Get image file names\n",
    "    images = []\n",
    "    for sample_dir in sample_dirs:\n",
    "        sample_dir = os.path.join(process_dir, sample_dir)\n",
    "        sample_images = [os.path.join(sample_dir, file) for file in os.listdir(sample_dir) if file.endswith(\".png\")]\n",
    "        sample_images.sort()\n",
    "        sample_images = list(reversed(sample_images))\n",
    "        images.append(sample_images)\n",
    "    images = np.array(images)\n",
    "\n",
    "    # Create gird of images at each diffusion time step\n",
    "    video = None\n",
    "    for t in tqdm(range(images.shape[1]), desc=\"Creating Video\"):\n",
    "        image_filenames_t = images[:,t]  # Get images at timestep t\n",
    "        images_t = [cv2.imread(image_filenames_t[i]) for i in range(images.shape[0])]  # Load images\n",
    "        grid_image = create_image_grid(images_t, grid_size)\n",
    "\n",
    "        # Initialize video writer\n",
    "        if video is None:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            video = cv2.VideoWriter(video_name, fourcc, fps, (grid_image.shape[1], grid_image.shape[0]))\n",
    "\n",
    "        # Write image to video\n",
    "        video.write(grid_image)\n",
    "\n",
    "    # Close the video writer\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a grid image from samples in a directory\n",
    "def create_sample_grid(sample_dir, output_file, grid_size):\n",
    "    images = [cv2.imread(os.path.join(sample_dir, file)) for file in os.listdir(sample_dir) if file.endswith(\".png\")]\n",
    "    grid_image = create_image_grid(images, grid_size)\n",
    "    cv2.imwrite(output_file, grid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a grid image showing the diffusion process for a single sample\n",
    "def create_process_image(process_sample_dir, output_file, grid_size):\n",
    "    # Get image file paths\n",
    "    images = [os.path.join(process_sample_dir, file) for file in os.listdir(process_sample_dir) if file.endswith(\".png\")]\n",
    "    images.sort()\n",
    "    images = list(reversed(images))\n",
    "    \n",
    "    # Select subset of images for grid\n",
    "    num_blocks = grid_size[0] * grid_size[1]\n",
    "    image_inds = np.linspace(0, len(images) - 1, num_blocks, dtype=int).tolist()\n",
    "    images = np.array(images)[image_inds]\n",
    "\n",
    "    # Load images\n",
    "    images = [cv2.imread(images[i]) for i in range(len(images))]\n",
    "\n",
    "    # Create and save grid\n",
    "    grid_image = create_image_grid(images, grid_size)\n",
    "    cv2.imwrite(output_file, grid_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "### Sample Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "checkpoint = torch.load(os.path.join(\"models\", Config.model_name, f\"{Config.checkpoint_name}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final samples only\n",
    "sample_model(checkpoint, num_batches=1, batch_size=Config.batch_size, save_process_imgs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final samples and intermediate diffusion images\n",
    "sample_model(checkpoint, num_batches=1, batch_size=Config.batch_size, save_process_imgs=True, num_steps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories containing images to be formatted for output\n",
    "single_sample_dir = os.path.join(\"samples\", Config.model_name, \"single\")\n",
    "process_sample_dir = os.path.join(\"samples\", Config.model_name, \"process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample grid\n",
    "create_sample_grid(single_sample_dir, \"output\\sample_grid.png\", grid_size=(5, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create process grid\n",
    "create_process_image(os.path.join(process_sample_dir, \"00003\"), \"output\\process_grid.png\", grid_size=(2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create video\n",
    "create_video(process_sample_dir, 'output\\diffusion.mp4', grid_size=(10, 16), fps=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee641",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
